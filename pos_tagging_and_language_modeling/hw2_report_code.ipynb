{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TTIC 31190\n",
    "### HW2\n",
    "#### Yingzi Jin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.initializers import RandomUniform\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    \"\"\"\n",
    "    Load tweet data from a file, returning tokens and POS tags.\n",
    "\n",
    "    Inputs:\n",
    "        filename (str): The name of the file to be read.\n",
    "\n",
    "    Returns:\n",
    "        - tokens (list of list of str): Tokens from the tweets.\n",
    "        - pos_tags (list of list of str): Corresponding POS tags.\n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as file:\n",
    "        tweets = file.read().strip().split('\\n\\n')\n",
    "\n",
    "    tokens = []\n",
    "    pos_tags = []\n",
    "\n",
    "    for tweet in tweets:\n",
    "        tk_lst, pos_lst = zip(*[item.split(\"\\t\") for item in tweet.split('\\n')])\n",
    "        tokens.append(list(tk_lst))\n",
    "        pos_tags.append(list(pos_lst))\n",
    "    \n",
    "\n",
    "    return tokens, pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokenizer(tokens):\n",
    "    \"\"\"\n",
    "    Create a tokenizer, fit it on a list of tokens\n",
    "\n",
    "    Inputs:\n",
    "        tokens (list of list of str): A list of tokenized text sequences.\n",
    "\n",
    "    Returns:\n",
    "        Tokenizer: A tokenizer object fit on the given tokens\n",
    "    \"\"\"\n",
    "    tokenizer = Tokenizer(oov_token=\"UNK\")\n",
    "    tokenizer.fit_on_texts(tokens)\n",
    "    \n",
    "    max_index = max(tokenizer.word_index.values())\n",
    "    tokenizer.word_index[\"<s>\"] = max_index + 1\n",
    "    tokenizer.word_index[\"</s>\"] = max_index + 2\n",
    "\n",
    "    return tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context_windows(X, w, tokenizer):\n",
    "    \"\"\"\n",
    "    Create context windows for each token in the given sentences\n",
    "\n",
    "    Inputs:\n",
    "        X (list of list of int): A list of sentences\n",
    "        w (int): The window size\n",
    "        tokenizer (Tokenizer): A tokenizer object \n",
    "\n",
    "    Returns:\n",
    "        A list of context windows, each represented as a list of token indices.\n",
    "    \"\"\"\n",
    "    context_windows = []\n",
    "\n",
    "    for sentence in X:\n",
    "        n = len(sentence)\n",
    "        extended_sentence = [tokenizer.word_index['<s>']] * w + sentence + [tokenizer.word_index['</s>']] * w\n",
    "\n",
    "        for i in range(w, len(extended_sentence) - w):\n",
    "            \n",
    "            window = extended_sentence[i-w : i+w+1]\n",
    "            context_windows.append(window)\n",
    "\n",
    "    \n",
    "    return context_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_x(tokens, w, tokenizer):\n",
    "    \"\"\"\n",
    "    Convert a list of tokenized sentences into numerical format and create \n",
    "        context windows for each token.\n",
    "\n",
    "    Inputs:\n",
    "        tokens (list of list of str): A list of tokenized text sequences.\n",
    "        w (int): The window size\n",
    "        tokenizer (Tokenizer): A tokenizer object \n",
    "\n",
    "    Returns:\n",
    "        A NumPy array containing the context windows for each token \n",
    "    \"\"\"\n",
    "    X = tokenizer.texts_to_sequences(tokens)\n",
    "    X_padded = create_context_windows(X, w, tokenizer)\n",
    "\n",
    "    return np.array(X_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labelencoder(pos_tags):\n",
    "    \"\"\"\n",
    "    Encode a list of POS tags into numerical labels and return the encoder and \n",
    "        encoded labels.\n",
    "\n",
    "    Inputs:\n",
    "        pos_tags (list of list of str): A list of lists where each inner list \n",
    "            contains POS tags of a sentence\n",
    "\n",
    "    Returns:\n",
    "        - label_encoder (LabelEncoder): The LabelEncoder object \n",
    "        - y_train (array): The encoded POS tags as a 1D NumPy array\n",
    "    \"\"\"\n",
    "\n",
    "    all_tags = [tag for tags in pos_tags for tag in tags]\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train = label_encoder.fit_transform(all_tags)\n",
    "\n",
    "    return label_encoder, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_y(pos_tags, label_encoder):\n",
    "    \"\"\"\n",
    "    Encode a list of POS tags into numerical labels using a given label encoder.\n",
    "\n",
    "    Inputs:\n",
    "        pos_tags (list of list of str): A list of lists where each inner list \n",
    "            contains POS tags of a sentence.\n",
    "    label_encoder (LabelEncoder): The LabelEncoder object\n",
    "\n",
    "    Returns:\n",
    "       The encoded POS tags as a 1D NumPy array\n",
    "    \"\"\"\n",
    "    all_tags = [tag for tags in pos_tags for tag in tags]\n",
    "    y = label_encoder.transform(all_tags)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'twpos-data/twpos-train.tsv'\n",
    "tokens, pos_tags = load_data(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = create_tokenizer(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0 = preprocess_x(tokens, 0, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = preprocess_x(tokens, 1, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder, y = create_labelencoder(pos_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'twpos-data/twpos-dev.tsv'\n",
    "tokens_dev, pos_tags_dev = load_data(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev_0 = preprocess_x(tokens_dev, 0, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev_1 = preprocess_x(tokens_dev, 1, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev = preprocess_y(pos_tags_dev, label_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEVTEST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'twpos-data/twpos-devtest.tsv'\n",
    "tokens_devtest, pos_tags_devtest = load_data(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_devtest_0 = preprocess_x(tokens_devtest, 0, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_devtest_1 = preprocess_x(tokens_devtest, 1, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_devtest = preprocess_y(pos_tags_devtest, label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data_0 = (X_dev_0, y_dev)\n",
    "dev_data_1 = (X_dev_1, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FFNN(tokenizer, label_encoder, w, seed=0, embedding_matrix=None, random_min=-0.01, \n",
    "         random_max=0.01, embedding_dim=50, features=None, trainable=True, \n",
    "         hidden_num=1, hidden_width=128, hidden_activation='tanh', optimizer=SGD, \n",
    "         learning_rate=0.02, \n",
    "         output_activation='softmax'):\n",
    "    \n",
    "    \"\"\"\n",
    "    Build and compile a Feed-Forward Neural Network (FFNN) using specified parameters.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    tf.random.set_seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    num_tags = len(label_encoder.classes_)\n",
    "\n",
    "    input_token = Input(shape=(1 + 2*w, ))  \n",
    "\n",
    "\n",
    "    if embedding_matrix is not None:\n",
    "        embedding = Embedding(input_dim=vocab_size, \n",
    "                              output_dim=embedding_dim,\n",
    "                              weights=[embedding_matrix],\n",
    "                              trainable=trainable)(input_token)\n",
    "    else:\n",
    "        embedding = Embedding(input_dim=vocab_size, \n",
    "                              output_dim=embedding_dim, \n",
    "                              embeddings_initializer=RandomUniform(minval=random_min, \n",
    "                                                                   maxval=random_max))(input_token)\n",
    "\n",
    "\n",
    "    flattened = Flatten()(embedding)\n",
    "    weights = flattened\n",
    "\n",
    "    if features is not None:\n",
    "        input_feature = Input(shape=(features.shape[1], ))\n",
    "        input_layer = [input_token, input_feature]\n",
    "        weights = Concatenate()([flattened, input_feature])\n",
    "        \n",
    "    else:\n",
    "        input_layer = input_token\n",
    "        \n",
    "    x = weights\n",
    "\n",
    "    for _ in range(hidden_num):\n",
    "        x = Dense(hidden_width, activation=hidden_activation)(x) \n",
    "    \n",
    "    \n",
    "    output = Dense(num_tags, activation=output_activation)(x)\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    model.compile(optimizer=optimizer(learning_rate), loss=SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(tokenizer, label_encoder, w, X, y, validation_data, \n",
    "                   X_test, y_test, embedding_matrix=None, features=None, \n",
    "                   trainable=True, hidden_num=1, hidden_width=128, optimizer=SGD, \n",
    "                   hidden_activation='tanh', output_activation='softmax', \n",
    "                   epochs=10, batch_size=1):\n",
    "    \"\"\"\n",
    "     Evaluate a FFNN model on specified validation and test data, with varying \n",
    "        random seeds.\n",
    "        \n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy',  \n",
    "                                   patience=2,  \n",
    "                                   restore_best_weights=True)\n",
    "\n",
    "    for seed in [0, 21, 42]:\n",
    "        model = FFNN(tokenizer, label_encoder, w, seed=seed, \n",
    "                     embedding_matrix=embedding_matrix, features=features, \n",
    "                     trainable=trainable, hidden_num=hidden_num,\n",
    "                     hidden_width=hidden_width, optimizer=optimizer, \n",
    "                     hidden_activation=hidden_activation, \n",
    "                     output_activation=output_activation)\n",
    "\n",
    "        model.fit(X, y, epochs=epochs, batch_size=batch_size, \n",
    "                  validation_data=validation_data, callbacks=[early_stopping])\n",
    "        loss, accuracy = model.evaluate(X_test, y_test)\n",
    "        \n",
    "        results[seed] = accuracy\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 34s 2ms/step - loss: 1.2941 - accuracy: 0.6193 - val_loss: 0.8760 - val_accuracy: 0.7420\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 33s 2ms/step - loss: 0.6092 - accuracy: 0.8392 - val_loss: 0.8242 - val_accuracy: 0.7654\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 41s 2ms/step - loss: 0.3877 - accuracy: 0.9024 - val_loss: 0.8010 - val_accuracy: 0.7658\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 40s 2ms/step - loss: 0.3183 - accuracy: 0.9135 - val_loss: 0.7704 - val_accuracy: 0.7820\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 33s 2ms/step - loss: 0.2849 - accuracy: 0.9144 - val_loss: 0.8053 - val_accuracy: 0.7774\n",
      "Epoch 6/10\n",
      "17130/17130 [==============================] - 42s 2ms/step - loss: 0.2653 - accuracy: 0.9161 - val_loss: 0.8158 - val_accuracy: 0.7669\n",
      "145/145 [==============================] - 1s 2ms/step - loss: 0.7040 - accuracy: 0.7946\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 56s 3ms/step - loss: 1.2897 - accuracy: 0.6235 - val_loss: 0.8724 - val_accuracy: 0.7542\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 52s 3ms/step - loss: 0.5955 - accuracy: 0.8424 - val_loss: 0.7910 - val_accuracy: 0.7675\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 53s 3ms/step - loss: 0.3770 - accuracy: 0.9049 - val_loss: 0.7824 - val_accuracy: 0.7791\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 39s 2ms/step - loss: 0.3117 - accuracy: 0.9152 - val_loss: 0.7884 - val_accuracy: 0.7776\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 40s 2ms/step - loss: 0.2798 - accuracy: 0.9158 - val_loss: 0.8466 - val_accuracy: 0.7747\n",
      "145/145 [==============================] - 1s 2ms/step - loss: 0.7088 - accuracy: 0.7954\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 43s 2ms/step - loss: 1.3150 - accuracy: 0.6095 - val_loss: 0.8813 - val_accuracy: 0.7357\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 38s 2ms/step - loss: 0.6011 - accuracy: 0.8391 - val_loss: 0.7913 - val_accuracy: 0.7722\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 35s 2ms/step - loss: 0.3730 - accuracy: 0.9033 - val_loss: 0.8239 - val_accuracy: 0.7669\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 37s 2ms/step - loss: 0.3102 - accuracy: 0.9142 - val_loss: 0.7984 - val_accuracy: 0.7673\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.7330 - accuracy: 0.7905\n"
     ]
    }
   ],
   "source": [
    "results_0_random = evaluate_model(tokenizer, label_encoder, 0, X_0, y, dev_data_0, \n",
    "                                  X_devtest_0, y_devtest, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 37s 2ms/step - loss: 1.1638 - accuracy: 0.6583 - val_loss: 0.7431 - val_accuracy: 0.7743\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 35s 2ms/step - loss: 0.4729 - accuracy: 0.8658 - val_loss: 0.7065 - val_accuracy: 0.8029\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 36s 2ms/step - loss: 0.2370 - accuracy: 0.9383 - val_loss: 0.7148 - val_accuracy: 0.8148\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 37s 2ms/step - loss: 0.1427 - accuracy: 0.9619 - val_loss: 0.7505 - val_accuracy: 0.8127\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 36s 2ms/step - loss: 0.0953 - accuracy: 0.9754 - val_loss: 0.7857 - val_accuracy: 0.8202\n",
      "Epoch 6/10\n",
      "17130/17130 [==============================] - 36s 2ms/step - loss: 0.0646 - accuracy: 0.9827 - val_loss: 0.8120 - val_accuracy: 0.8146\n",
      "Epoch 7/10\n",
      "17130/17130 [==============================] - 36s 2ms/step - loss: 0.0479 - accuracy: 0.9877 - val_loss: 0.8359 - val_accuracy: 0.8162\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.6677 - accuracy: 0.8304\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 38s 2ms/step - loss: 1.1776 - accuracy: 0.6546 - val_loss: 0.7623 - val_accuracy: 0.7801\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 38s 2ms/step - loss: 0.4782 - accuracy: 0.8643 - val_loss: 0.6657 - val_accuracy: 0.8108\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 37s 2ms/step - loss: 0.2395 - accuracy: 0.9371 - val_loss: 0.6806 - val_accuracy: 0.8177\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 37s 2ms/step - loss: 0.1458 - accuracy: 0.9607 - val_loss: 0.7552 - val_accuracy: 0.8075\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 38s 2ms/step - loss: 0.0981 - accuracy: 0.9724 - val_loss: 0.8171 - val_accuracy: 0.8069\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.5934 - accuracy: 0.8362\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 38s 2ms/step - loss: 1.1771 - accuracy: 0.6546 - val_loss: 0.7704 - val_accuracy: 0.7720\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 37s 2ms/step - loss: 0.4841 - accuracy: 0.8573 - val_loss: 0.6622 - val_accuracy: 0.8096\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 36s 2ms/step - loss: 0.2409 - accuracy: 0.9364 - val_loss: 0.6696 - val_accuracy: 0.8193\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 40s 2ms/step - loss: 0.1432 - accuracy: 0.9602 - val_loss: 0.7299 - val_accuracy: 0.8121\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 33s 2ms/step - loss: 0.0963 - accuracy: 0.9731 - val_loss: 0.7755 - val_accuracy: 0.8141\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.5912 - accuracy: 0.8291\n"
     ]
    }
   ],
   "source": [
    "results_1_random = evaluate_model(tokenizer, label_encoder, 1, X_1, y, dev_data_1, \n",
    "                                  X_devtest_1, y_devtest, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.7945678234100342, 21: 0.795430064201355, 42: 0.7904720902442932}"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_0_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.8303513526916504, 21: 0.836171567440033, 42: 0.8290579915046692}"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_1_random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When w = 0, the accuracies on the devtest for three different random seeds are:\n",
    "\n",
    "        (0.7945678234100342, 0.795430064201355, 0.7904720902442932)\n",
    "\n",
    "- When w = 1, the accuracies on the devtest for three different random seeds are:\n",
    "\n",
    "        (0.8303513526916504, 0.836171567440033, 0.8290579915046692)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_org = \"twpos-data/orig-train.tsv\"\n",
    "filename_dev_org = \"twpos-data/orig-dev.tsv\"\n",
    "filename_devtest_org = \"twpos-data/orig-devtest.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_org, _ = load_data(filename_org)\n",
    "tokens_dev_org, _ = load_data(filename_dev_org)\n",
    "tokens_devtest_org, _ = load_data(filename_devtest_org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Features selected: \n",
    "    - whether the first letter is capitalized\n",
    "    - whether the token is digit\n",
    "    - whether the token contains:\n",
    "        - \\#\n",
    "        - @\n",
    "        - http\n",
    "    - whether the token ends with:\n",
    "        - ing\n",
    "        - ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(tokens_list):\n",
    "    \"\"\"\n",
    "    Extract a set of features from a list of tokenized sentences for each token.\n",
    "\n",
    "    Inputs:\n",
    "        tokens_list (list of list of str): A list of tokenized text sequences\n",
    "\n",
    "    Returns:\n",
    "        A NumPy array containing the extracted features for each token\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    for tokens in tokens_list:\n",
    "        for token in tokens:\n",
    "            is_capitalized = float(token[0].isupper())\n",
    "            is_numeric = float(token.isdigit())\n",
    "            contains_hash = float(\"#\" in token)\n",
    "            contains_at = float(\"@\" in token)\n",
    "            contains_http = float(\"http\" in token)\n",
    "            end_ing = float(token[-3:] == \"ing\")\n",
    "            end_ed = float(token[-2:] == \"ed\")\n",
    "            length = len(token)\n",
    "            features.append([is_capitalized, is_numeric, contains_hash, contains_at,\n",
    "                             contains_http, end_ing, end_ed, length])\n",
    "\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = create_features(tokens)\n",
    "features_dev = create_features(tokens_dev)\n",
    "features_devtest = create_features(tokens_devtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features_0 = [X_0, features_train]\n",
    "X_train_features_1 = [X_1, features_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data_features_0 = ([X_dev_0, features_dev], y_dev)\n",
    "dev_data_features_1 = ([X_dev_1, features_dev], y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_devtest_features_0 = [X_devtest_0,features_devtest]\n",
    "X_devtest_features_1 = [X_devtest_1,features_devtest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 27s 2ms/step - loss: 1.3794 - accuracy: 0.5725 - val_loss: 0.9203 - val_accuracy: 0.7117\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 25s 1ms/step - loss: 0.7999 - accuracy: 0.7457 - val_loss: 0.9202 - val_accuracy: 0.7003\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 26s 1ms/step - loss: 0.5769 - accuracy: 0.8192 - val_loss: 0.7784 - val_accuracy: 0.7851\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 26s 2ms/step - loss: 0.4352 - accuracy: 0.8743 - val_loss: 0.7653 - val_accuracy: 0.7799\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 28s 2ms/step - loss: 0.3632 - accuracy: 0.8990 - val_loss: 0.7988 - val_accuracy: 0.7828\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.7318 - accuracy: 0.7892\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 29s 2ms/step - loss: 1.3746 - accuracy: 0.5760 - val_loss: 0.9711 - val_accuracy: 0.6548\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 30s 2ms/step - loss: 0.7879 - accuracy: 0.7563 - val_loss: 0.7817 - val_accuracy: 0.7722\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 27s 2ms/step - loss: 0.5627 - accuracy: 0.8236 - val_loss: 0.7477 - val_accuracy: 0.7766\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 27s 2ms/step - loss: 0.4278 - accuracy: 0.8756 - val_loss: 0.7461 - val_accuracy: 0.8009\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 26s 2ms/step - loss: 0.3468 - accuracy: 0.9006 - val_loss: 0.7898 - val_accuracy: 0.7776\n",
      "Epoch 6/10\n",
      "17130/17130 [==============================] - 27s 2ms/step - loss: 0.3141 - accuracy: 0.9077 - val_loss: 0.7716 - val_accuracy: 0.7882\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.6818 - accuracy: 0.8064\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 28s 2ms/step - loss: 1.3857 - accuracy: 0.5712 - val_loss: 0.9196 - val_accuracy: 0.7194\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 27s 2ms/step - loss: 0.7919 - accuracy: 0.7493 - val_loss: 0.8094 - val_accuracy: 0.7683\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 27s 2ms/step - loss: 0.5691 - accuracy: 0.8254 - val_loss: 0.7891 - val_accuracy: 0.7855\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 27s 2ms/step - loss: 0.4241 - accuracy: 0.8806 - val_loss: 0.8119 - val_accuracy: 0.7874\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 27s 2ms/step - loss: 0.3579 - accuracy: 0.8971 - val_loss: 0.8922 - val_accuracy: 0.7824\n",
      "Epoch 6/10\n",
      "17130/17130 [==============================] - 26s 2ms/step - loss: 0.3196 - accuracy: 0.9068 - val_loss: 0.7623 - val_accuracy: 0.7980\n",
      "Epoch 7/10\n",
      "17130/17130 [==============================] - 27s 2ms/step - loss: 0.2914 - accuracy: 0.9117 - val_loss: 0.7923 - val_accuracy: 0.7965\n",
      "Epoch 8/10\n",
      "17130/17130 [==============================] - 26s 2ms/step - loss: 0.2777 - accuracy: 0.9126 - val_loss: 0.7904 - val_accuracy: 0.8017\n",
      "Epoch 9/10\n",
      "17130/17130 [==============================] - 26s 2ms/step - loss: 0.2642 - accuracy: 0.9163 - val_loss: 0.8089 - val_accuracy: 0.7998\n",
      "Epoch 10/10\n",
      "17130/17130 [==============================] - 27s 2ms/step - loss: 0.2530 - accuracy: 0.9191 - val_loss: 0.8523 - val_accuracy: 0.7913\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.7395 - accuracy: 0.8043\n"
     ]
    }
   ],
   "source": [
    "results_0_random_features = evaluate_model(tokenizer, label_encoder, 0, \n",
    "                                           X_train_features_0, y, \n",
    "                                           dev_data_features_0, \n",
    "                                           X_devtest_features_0,\n",
    "                                           y_devtest,features=features_train, \n",
    "                                           batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 28s 2ms/step - loss: 1.2783 - accuracy: 0.6061 - val_loss: 0.8083 - val_accuracy: 0.7418\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 26s 2ms/step - loss: 0.6853 - accuracy: 0.7813 - val_loss: 0.7644 - val_accuracy: 0.7563\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 26s 2ms/step - loss: 0.4601 - accuracy: 0.8568 - val_loss: 0.6218 - val_accuracy: 0.8309\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 27s 2ms/step - loss: 0.3078 - accuracy: 0.9110 - val_loss: 0.6625 - val_accuracy: 0.8316\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 26s 2ms/step - loss: 0.2213 - accuracy: 0.9388 - val_loss: 0.7292 - val_accuracy: 0.8150\n",
      "Epoch 6/10\n",
      "17130/17130 [==============================] - 26s 2ms/step - loss: 0.1627 - accuracy: 0.9530 - val_loss: 0.7420 - val_accuracy: 0.8270\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.5997 - accuracy: 0.8388\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 27s 2ms/step - loss: 1.2917 - accuracy: 0.6047 - val_loss: 1.1204 - val_accuracy: 0.6569\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 26s 2ms/step - loss: 0.6873 - accuracy: 0.7881 - val_loss: 0.6879 - val_accuracy: 0.7996\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 26s 2ms/step - loss: 0.4688 - accuracy: 0.8549 - val_loss: 0.6531 - val_accuracy: 0.8218\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 26s 2ms/step - loss: 0.3146 - accuracy: 0.9093 - val_loss: 0.6936 - val_accuracy: 0.8253\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 27s 2ms/step - loss: 0.2185 - accuracy: 0.9376 - val_loss: 0.7510 - val_accuracy: 0.7992\n",
      "Epoch 6/10\n",
      "17130/17130 [==============================] - 26s 2ms/step - loss: 0.1604 - accuracy: 0.9524 - val_loss: 0.7401 - val_accuracy: 0.8324\n",
      "Epoch 7/10\n",
      "17130/17130 [==============================] - 26s 2ms/step - loss: 0.1195 - accuracy: 0.9646 - val_loss: 0.8174 - val_accuracy: 0.8185\n",
      "Epoch 8/10\n",
      "17130/17130 [==============================] - 27s 2ms/step - loss: 0.0905 - accuracy: 0.9744 - val_loss: 0.7904 - val_accuracy: 0.8243\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.6466 - accuracy: 0.8444\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 27s 2ms/step - loss: 1.2755 - accuracy: 0.6088 - val_loss: 0.7876 - val_accuracy: 0.7554\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 26s 2ms/step - loss: 0.6717 - accuracy: 0.7856 - val_loss: 0.7187 - val_accuracy: 0.7878\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 27s 2ms/step - loss: 0.4432 - accuracy: 0.8608 - val_loss: 0.6381 - val_accuracy: 0.8291\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 27s 2ms/step - loss: 0.2906 - accuracy: 0.9145 - val_loss: 0.6944 - val_accuracy: 0.8222\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 26s 2ms/step - loss: 0.2137 - accuracy: 0.9373 - val_loss: 1.0095 - val_accuracy: 0.7808\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.5887 - accuracy: 0.8366\n"
     ]
    }
   ],
   "source": [
    "results_1_random_features = evaluate_model(tokenizer, label_encoder, 1, \n",
    "                                           X_train_features_1, y, \n",
    "                                           dev_data_features_1, \n",
    "                                           X_devtest_features_1,\n",
    "                                           y_devtest,features=features_train, \n",
    "                                           batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.789178729057312, 21: 0.8064237833023071, 42: 0.8042681813240051}"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_0_random_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.8387583494186401, 21: 0.8443630337715149, 42: 0.8366026878356934}"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_1_random_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.8303513526916504, 21: 0.836171567440033, 42: 0.8290579915046692}"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_1_random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When w = 0, for each random seed, adding features changes the accuracies from:\n",
    "    \n",
    "        0.7945678234100342 -> 0.789178729057312\n",
    "\n",
    "        0.795430064201355 -> 0.8064237833023071\n",
    "\n",
    "        0.7904720902442932 -> 0.8042681813240051\n",
    "\n",
    "- When w = 1, for each random seed, adding features changes the accuracies from:\n",
    "    \n",
    "        0.8303513526916504 -> 0.8387583494186401\n",
    "\n",
    "        0.836171567440033 -> 0.8443630337715149\n",
    "        \n",
    "        0.8290579915046692 -> 0.8366026878356934\n",
    "\n",
    "\n",
    "- When w = 0, two out of three times adding features improved the accuracies. \n",
    "\n",
    "- When w = 1, all three times adding features improved the accuracies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Updating the pretrained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(filename):\n",
    "    \"\"\"\n",
    "    Load pre-trained word embeddings from a file into a dictionary.\n",
    "\n",
    "    Inputs:\n",
    "        filename (str): The name of the file containing the pre-trained word \n",
    "            embeddings\n",
    "\n",
    "    Returns:\n",
    "        A dictionary where keys are words and values are embedding vectors as \n",
    "            NumPy arrays\n",
    "    \"\"\"\n",
    "    \n",
    "    embedding_dict = {}\n",
    "\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float64')\n",
    "            embedding_dict[word] = vector\n",
    "\n",
    "    return embedding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedd_file = 'twitter-embeddings.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dict = load_embeddings(embedd_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dict[\"<s>\"] = embedding_dict[\"</s>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(tokenizer, embedding_dict):\n",
    "    \"\"\"\n",
    "    Create an embedding matrix for the vocabulary based on pre-trained word \n",
    "        embeddings.\n",
    "\n",
    "    Inputs:\n",
    "        tokenizer (Tokenizer): A tokenizer object \n",
    "        embedding_dict (dict): A dictionary containing pre-trained word embeddings.\n",
    "\n",
    "    Returns:\n",
    "        An embedding matrix where each row corresponds to a word in the vocabulary.\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    embedding_dim = 50\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "\n",
    "        if word in embedding_dict:\n",
    "            embedding_matrix[i] = embedding_dict.get(word)\n",
    "        else:\n",
    "            embedding_matrix[i] = embedding_dict.get(\"UUUNKKK\")\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = create_embedding_matrix(tokenizer, embedding_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.7144 - accuracy: 0.7986 - val_loss: 0.7374 - val_accuracy: 0.7754\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 23s 1ms/step - loss: 0.4171 - accuracy: 0.8717 - val_loss: 0.7475 - val_accuracy: 0.7691\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 23s 1ms/step - loss: 0.3128 - accuracy: 0.9068 - val_loss: 0.7640 - val_accuracy: 0.7691\n",
      "145/145 [==============================] - 0s 867us/step - loss: 0.6988 - accuracy: 0.7840\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.7122 - accuracy: 0.8025 - val_loss: 0.7470 - val_accuracy: 0.7797\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.4113 - accuracy: 0.8764 - val_loss: 0.7236 - val_accuracy: 0.7739\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.3116 - accuracy: 0.9060 - val_loss: 0.7424 - val_accuracy: 0.7729\n",
      "145/145 [==============================] - 0s 882us/step - loss: 0.7115 - accuracy: 0.7894\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.7150 - accuracy: 0.7987 - val_loss: 0.8109 - val_accuracy: 0.7654\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.4113 - accuracy: 0.8730 - val_loss: 0.7424 - val_accuracy: 0.7729\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.3124 - accuracy: 0.9058 - val_loss: 0.7824 - val_accuracy: 0.7623\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.2689 - accuracy: 0.9161 - val_loss: 0.7867 - val_accuracy: 0.7639\n",
      "145/145 [==============================] - 0s 903us/step - loss: 0.6802 - accuracy: 0.7853\n"
     ]
    }
   ],
   "source": [
    "results_0_pretrained = evaluate_model(tokenizer, label_encoder, 0, \n",
    "                                      X_0, y, \n",
    "                                      dev_data_0, \n",
    "                                      X_devtest_0,y_devtest,\n",
    "                                      embedding_matrix=embedding_matrix,\n",
    "                                      batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.6435 - accuracy: 0.8180 - val_loss: 0.6177 - val_accuracy: 0.8150\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.3026 - accuracy: 0.9083 - val_loss: 0.6483 - val_accuracy: 0.8158\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.1730 - accuracy: 0.9503 - val_loss: 0.7003 - val_accuracy: 0.8195\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.1083 - accuracy: 0.9688 - val_loss: 0.7406 - val_accuracy: 0.8179\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.0741 - accuracy: 0.9806 - val_loss: 0.7863 - val_accuracy: 0.8303\n",
      "Epoch 6/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.0522 - accuracy: 0.9855 - val_loss: 0.8437 - val_accuracy: 0.8204\n",
      "Epoch 7/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.0361 - accuracy: 0.9902 - val_loss: 0.8764 - val_accuracy: 0.8197\n",
      "145/145 [==============================] - 0s 922us/step - loss: 0.6949 - accuracy: 0.8332\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 25s 1ms/step - loss: 0.6405 - accuracy: 0.8207 - val_loss: 0.6205 - val_accuracy: 0.8231\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.3051 - accuracy: 0.9091 - val_loss: 0.6038 - val_accuracy: 0.8291\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.1742 - accuracy: 0.9493 - val_loss: 0.6704 - val_accuracy: 0.8264\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.1111 - accuracy: 0.9698 - val_loss: 0.7193 - val_accuracy: 0.8224\n",
      "145/145 [==============================] - 0s 875us/step - loss: 0.5418 - accuracy: 0.8409\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.6423 - accuracy: 0.8187 - val_loss: 0.6928 - val_accuracy: 0.7930\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 23s 1ms/step - loss: 0.3005 - accuracy: 0.9106 - val_loss: 0.6083 - val_accuracy: 0.8260\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 23s 1ms/step - loss: 0.1734 - accuracy: 0.9508 - val_loss: 0.6898 - val_accuracy: 0.8212\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 26s 2ms/step - loss: 0.1076 - accuracy: 0.9705 - val_loss: 0.7761 - val_accuracy: 0.8185\n",
      "145/145 [==============================] - 0s 997us/step - loss: 0.5524 - accuracy: 0.8306\n"
     ]
    }
   ],
   "source": [
    "results_1_pretrained = evaluate_model(tokenizer, label_encoder, 1, \n",
    "                                      X_1, y, \n",
    "                                      dev_data_1, \n",
    "                                      X_devtest_1,y_devtest,\n",
    "                                      embedding_matrix=embedding_matrix,\n",
    "                                      batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.7840051651000977, 21: 0.7893942594528198, 42: 0.7852985262870789}"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_0_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.8331537246704102, 21: 0.8409140110015869, 42: 0.830566942691803}"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_1_pretrained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When w = 0, for each random seed, pretrained embeddings changes the accuracies from:\n",
    "    \n",
    "        0.7945678234100342 -> 0.7840051651000977\n",
    "\n",
    "        0.795430064201355 -> 0.7893942594528198\n",
    "\n",
    "        0.7904720902442932 -> 0.7852985262870789\n",
    "\n",
    "- When w = 1, for each random seed, pretrained embeddings changes the accuracies from:\n",
    "    \n",
    "        0.8303513526916504 -> 0.8331537246704102\n",
    "\n",
    "        0.836171567440033 -> 0.8409140110015869\n",
    "        \n",
    "        0.8290579915046692 -> 0.830566942691803\n",
    "\n",
    "\n",
    "- When w = 0, the accuracies were not improved by the pretrained embeddings. \n",
    "\n",
    "- However, when w = 1, all three times the pretrained embeddings improved the accuracies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fixed pretrained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 20s 1ms/step - loss: 0.7889 - accuracy: 0.7785 - val_loss: 0.8111 - val_accuracy: 0.7583\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 23s 1ms/step - loss: 0.5623 - accuracy: 0.8342 - val_loss: 0.7828 - val_accuracy: 0.7687\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 20s 1ms/step - loss: 0.5222 - accuracy: 0.8465 - val_loss: 0.7680 - val_accuracy: 0.7745\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 21s 1ms/step - loss: 0.5004 - accuracy: 0.8494 - val_loss: 0.7591 - val_accuracy: 0.7808\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 20s 1ms/step - loss: 0.4774 - accuracy: 0.8558 - val_loss: 0.7844 - val_accuracy: 0.7814\n",
      "Epoch 6/10\n",
      "17130/17130 [==============================] - 19s 1ms/step - loss: 0.4591 - accuracy: 0.8612 - val_loss: 0.7600 - val_accuracy: 0.7814\n",
      "Epoch 7/10\n",
      "17130/17130 [==============================] - 19s 1ms/step - loss: 0.4444 - accuracy: 0.8657 - val_loss: 0.7544 - val_accuracy: 0.7853\n",
      "Epoch 8/10\n",
      "17130/17130 [==============================] - 18s 1ms/step - loss: 0.4225 - accuracy: 0.8701 - val_loss: 0.7866 - val_accuracy: 0.7704\n",
      "Epoch 9/10\n",
      "17130/17130 [==============================] - 18s 1ms/step - loss: 0.4061 - accuracy: 0.8751 - val_loss: 0.7757 - val_accuracy: 0.7787\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.7099 - accuracy: 0.7918\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 19s 1ms/step - loss: 0.7845 - accuracy: 0.7811 - val_loss: 0.8505 - val_accuracy: 0.7498\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 18s 1ms/step - loss: 0.5592 - accuracy: 0.8356 - val_loss: 0.7797 - val_accuracy: 0.7710\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 19s 1ms/step - loss: 0.5233 - accuracy: 0.8450 - val_loss: 0.7600 - val_accuracy: 0.7828\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 19s 1ms/step - loss: 0.4979 - accuracy: 0.8521 - val_loss: 0.7697 - val_accuracy: 0.7772\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 18s 1ms/step - loss: 0.4786 - accuracy: 0.8543 - val_loss: 0.7911 - val_accuracy: 0.7627\n",
      "145/145 [==============================] - 0s 954us/step - loss: 0.7260 - accuracy: 0.7840\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 19s 1ms/step - loss: 0.7853 - accuracy: 0.7785 - val_loss: 0.8902 - val_accuracy: 0.7380\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 18s 1ms/step - loss: 0.5595 - accuracy: 0.8356 - val_loss: 0.7937 - val_accuracy: 0.7602\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 18s 1ms/step - loss: 0.5188 - accuracy: 0.8434 - val_loss: 0.7507 - val_accuracy: 0.7756\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 20s 1ms/step - loss: 0.4960 - accuracy: 0.8513 - val_loss: 0.7953 - val_accuracy: 0.7691\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 19s 1ms/step - loss: 0.4765 - accuracy: 0.8555 - val_loss: 0.7774 - val_accuracy: 0.7770\n",
      "Epoch 6/10\n",
      "17130/17130 [==============================] - 20s 1ms/step - loss: 0.4566 - accuracy: 0.8615 - val_loss: 0.7735 - val_accuracy: 0.7691\n",
      "Epoch 7/10\n",
      "17130/17130 [==============================] - 19s 1ms/step - loss: 0.4370 - accuracy: 0.8678 - val_loss: 0.7803 - val_accuracy: 0.7787\n",
      "Epoch 8/10\n",
      "17130/17130 [==============================] - 18s 1ms/step - loss: 0.4193 - accuracy: 0.8727 - val_loss: 0.7584 - val_accuracy: 0.7847\n",
      "Epoch 9/10\n",
      "17130/17130 [==============================] - 19s 1ms/step - loss: 0.4024 - accuracy: 0.8745 - val_loss: 0.7638 - val_accuracy: 0.7864\n",
      "Epoch 10/10\n",
      "17130/17130 [==============================] - 19s 1ms/step - loss: 0.3880 - accuracy: 0.8792 - val_loss: 0.7652 - val_accuracy: 0.7866\n",
      "145/145 [==============================] - 0s 955us/step - loss: 0.7264 - accuracy: 0.7851\n"
     ]
    }
   ],
   "source": [
    "results_1_fixed_pretrained = evaluate_model(tokenizer, label_encoder, 1, \n",
    "                                            X_1, y, \n",
    "                                            dev_data_1, \n",
    "                                            X_devtest_1,y_devtest,\n",
    "                                            trainable=False,\n",
    "                                            embedding_matrix=embedding_matrix,\n",
    "                                            batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.7917654514312744, 21: 0.7840051651000977, 42: 0.785082995891571}"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_1_fixed_pretrained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When w = 1, for each random seed, fixed pretrained embeddings changes the accuracies from:\n",
    "    \n",
    "        0.8331537246704102 -> 0.7917654514312744\n",
    "\n",
    "        0.8409140110015869 -> 0.7840051651000977\n",
    "        \n",
    "        0.830566942691803 -> 0.785082995891571\n",
    "\n",
    "\n",
    "- When w = 1, compared with updating pretrained embeddings, the fixed pretrained embeddings impair the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pretrained embeddings with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.8087 - accuracy: 0.7638 - val_loss: 0.7841 - val_accuracy: 0.7679\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.5057 - accuracy: 0.8461 - val_loss: 0.9590 - val_accuracy: 0.7117\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 25s 1ms/step - loss: 0.3995 - accuracy: 0.8741 - val_loss: 0.7994 - val_accuracy: 0.7552\n",
      "145/145 [==============================] - 0s 885us/step - loss: 0.7532 - accuracy: 0.7659\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 27s 1ms/step - loss: 0.8055 - accuracy: 0.7692 - val_loss: 0.7938 - val_accuracy: 0.7552\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.4980 - accuracy: 0.8488 - val_loss: 0.7018 - val_accuracy: 0.7890\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.4018 - accuracy: 0.8720 - val_loss: 0.7449 - val_accuracy: 0.7907\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.3310 - accuracy: 0.8973 - val_loss: 0.7362 - val_accuracy: 0.7899\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.2926 - accuracy: 0.9062 - val_loss: 0.8158 - val_accuracy: 0.7594\n",
      "145/145 [==============================] - 0s 956us/step - loss: 0.6922 - accuracy: 0.7963\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 25s 1ms/step - loss: 0.8121 - accuracy: 0.7659 - val_loss: 0.8299 - val_accuracy: 0.7540\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.5017 - accuracy: 0.8438 - val_loss: 0.7035 - val_accuracy: 0.7828\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.3997 - accuracy: 0.8734 - val_loss: 0.8660 - val_accuracy: 0.7718\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.3315 - accuracy: 0.8962 - val_loss: 0.7407 - val_accuracy: 0.7832\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.2943 - accuracy: 0.9036 - val_loss: 0.9558 - val_accuracy: 0.7789\n",
      "Epoch 6/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.2738 - accuracy: 0.9110 - val_loss: 0.7387 - val_accuracy: 0.7895\n",
      "Epoch 7/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.2542 - accuracy: 0.9157 - val_loss: 0.7441 - val_accuracy: 0.7722\n",
      "Epoch 8/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.2450 - accuracy: 0.9150 - val_loss: 0.7464 - val_accuracy: 0.8061\n",
      "Epoch 9/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.2347 - accuracy: 0.9180 - val_loss: 0.7348 - val_accuracy: 0.8056\n",
      "Epoch 10/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.2268 - accuracy: 0.9221 - val_loss: 0.8098 - val_accuracy: 0.7851\n",
      "145/145 [==============================] - 0s 903us/step - loss: 0.6861 - accuracy: 0.8064\n"
     ]
    }
   ],
   "source": [
    "results_0_pretrained_features = evaluate_model(tokenizer, label_encoder, 0, \n",
    "                                               X_train_features_0, y, \n",
    "                                               dev_data_features_0, \n",
    "                                               X_devtest_features_0,y_devtest,\n",
    "                                               features=features_train,\n",
    "                                               embedding_matrix=embedding_matrix,\n",
    "                                               batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 25s 1ms/step - loss: 0.7301 - accuracy: 0.7887 - val_loss: 0.6208 - val_accuracy: 0.8114\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.3892 - accuracy: 0.8820 - val_loss: 0.8526 - val_accuracy: 0.7610\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.2643 - accuracy: 0.9207 - val_loss: 0.6506 - val_accuracy: 0.8237\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.1849 - accuracy: 0.9439 - val_loss: 0.6478 - val_accuracy: 0.8388\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.1380 - accuracy: 0.9586 - val_loss: 0.6966 - val_accuracy: 0.8388\n",
      "Epoch 6/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.1016 - accuracy: 0.9680 - val_loss: 0.7552 - val_accuracy: 0.8251\n",
      "145/145 [==============================] - 0s 908us/step - loss: 0.5968 - accuracy: 0.8362\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 25s 1ms/step - loss: 0.7283 - accuracy: 0.7877 - val_loss: 0.7359 - val_accuracy: 0.7702\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.3871 - accuracy: 0.8832 - val_loss: 0.5922 - val_accuracy: 0.8268\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.2701 - accuracy: 0.9179 - val_loss: 0.5707 - val_accuracy: 0.8444\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.1825 - accuracy: 0.9434 - val_loss: 0.6191 - val_accuracy: 0.8372\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.1344 - accuracy: 0.9598 - val_loss: 0.7457 - val_accuracy: 0.8218\n",
      "145/145 [==============================] - 0s 919us/step - loss: 0.5130 - accuracy: 0.8444\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 25s 1ms/step - loss: 0.7339 - accuracy: 0.7873 - val_loss: 0.8136 - val_accuracy: 0.7756\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.3880 - accuracy: 0.8824 - val_loss: 0.5627 - val_accuracy: 0.8388\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.2687 - accuracy: 0.9190 - val_loss: 0.7167 - val_accuracy: 0.8073\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 24s 1ms/step - loss: 0.1816 - accuracy: 0.9464 - val_loss: 0.6816 - val_accuracy: 0.8216\n",
      "145/145 [==============================] - 0s 894us/step - loss: 0.5269 - accuracy: 0.8441\n"
     ]
    }
   ],
   "source": [
    "results_1_pretrained_features = evaluate_model(tokenizer, label_encoder, 1, \n",
    "                                               X_train_features_1, y, \n",
    "                                               dev_data_features_1, \n",
    "                                               X_devtest_features_1,y_devtest,\n",
    "                                               features=features_train,\n",
    "                                               embedding_matrix=embedding_matrix,\n",
    "                                               batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.765897810459137, 21: 0.7962923049926758, 42: 0.8064237833023071}"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_0_pretrained_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.836171567440033, 21: 0.8443630337715149, 42: 0.8441474437713623}"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_1_pretrained_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When w = 0, for each random seed, adding features changes the accuracies from:\n",
    "    \n",
    "        0.7840051651000977 -> 0.765897810459137\n",
    "\n",
    "        0.7893942594528198 -> 0.7962923049926758\n",
    "\n",
    "        0.7852985262870789 -> 0.8064237833023071\n",
    "\n",
    "- When w = 1, for each random seed, adding features changes the accuracies from:\n",
    "    \n",
    "        0.8331537246704102 -> 0.836171567440033\n",
    "\n",
    "        0.8409140110015869 -> 0.8443630337715149\n",
    "        \n",
    "        0.830566942691803 -> 0.8441474437713623\n",
    "\n",
    "\n",
    "When w = 0, two out of three times adding features improved the accuracies. \n",
    "\n",
    "When w = 1, all three times adding features improved the accuracies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Number of hidden layers X Hidden widths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_nums = [0, 1, 2]\n",
    "hidden_widths = [256, 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 40s 2ms/step - loss: 0.8567 - accuracy: 0.7754 - val_loss: 0.6331 - val_accuracy: 0.8168\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 40s 2ms/step - loss: 0.4154 - accuracy: 0.8830 - val_loss: 0.6891 - val_accuracy: 0.7909\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 39s 2ms/step - loss: 0.2963 - accuracy: 0.9159 - val_loss: 0.5612 - val_accuracy: 0.8428\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 40s 2ms/step - loss: 0.2192 - accuracy: 0.9412 - val_loss: 0.5394 - val_accuracy: 0.8448\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 40s 2ms/step - loss: 0.1674 - accuracy: 0.9563 - val_loss: 0.5498 - val_accuracy: 0.8403\n",
      "Epoch 6/10\n",
      "17130/17130 [==============================] - 40s 2ms/step - loss: 0.1319 - accuracy: 0.9665 - val_loss: 0.5537 - val_accuracy: 0.8421\n",
      "145/145 [==============================] - 1s 2ms/step - loss: 0.4996 - accuracy: 0.8504\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 42s 2ms/step - loss: 0.8693 - accuracy: 0.7726 - val_loss: 0.7003 - val_accuracy: 0.7911\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 42s 2ms/step - loss: 0.4140 - accuracy: 0.8830 - val_loss: 0.5630 - val_accuracy: 0.8365\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 40s 2ms/step - loss: 0.2969 - accuracy: 0.9149 - val_loss: 0.5273 - val_accuracy: 0.8463\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 40s 2ms/step - loss: 0.2174 - accuracy: 0.9413 - val_loss: 0.5248 - val_accuracy: 0.8430\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 41s 2ms/step - loss: 0.1651 - accuracy: 0.9577 - val_loss: 0.5621 - val_accuracy: 0.8378\n",
      "145/145 [==============================] - 1s 3ms/step - loss: 0.4925 - accuracy: 0.8534\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 41s 2ms/step - loss: 0.8622 - accuracy: 0.7720 - val_loss: 0.7650 - val_accuracy: 0.7828\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 40s 2ms/step - loss: 0.4143 - accuracy: 0.8825 - val_loss: 0.5519 - val_accuracy: 0.8359\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 40s 2ms/step - loss: 0.2944 - accuracy: 0.9170 - val_loss: 0.6143 - val_accuracy: 0.8162\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 40s 2ms/step - loss: 0.2185 - accuracy: 0.9406 - val_loss: 0.5482 - val_accuracy: 0.8378\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 40s 2ms/step - loss: 0.1685 - accuracy: 0.9559 - val_loss: 0.5609 - val_accuracy: 0.8359\n",
      "Epoch 6/10\n",
      "17130/17130 [==============================] - 41s 2ms/step - loss: 0.1295 - accuracy: 0.9668 - val_loss: 0.5609 - val_accuracy: 0.8374\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.8495\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 41s 2ms/step - loss: 0.8567 - accuracy: 0.7754 - val_loss: 0.6331 - val_accuracy: 0.8168\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 40s 2ms/step - loss: 0.4154 - accuracy: 0.8830 - val_loss: 0.6891 - val_accuracy: 0.7909\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 40s 2ms/step - loss: 0.2963 - accuracy: 0.9159 - val_loss: 0.5612 - val_accuracy: 0.8428\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 40s 2ms/step - loss: 0.2192 - accuracy: 0.9412 - val_loss: 0.5394 - val_accuracy: 0.8448\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 40s 2ms/step - loss: 0.1674 - accuracy: 0.9563 - val_loss: 0.5498 - val_accuracy: 0.8403\n",
      "Epoch 6/10\n",
      "17130/17130 [==============================] - 41s 2ms/step - loss: 0.1319 - accuracy: 0.9665 - val_loss: 0.5537 - val_accuracy: 0.8421\n",
      "145/145 [==============================] - 1s 2ms/step - loss: 0.4996 - accuracy: 0.8504\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 38s 2ms/step - loss: 0.8693 - accuracy: 0.7726 - val_loss: 0.7003 - val_accuracy: 0.7911\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 38s 2ms/step - loss: 0.4140 - accuracy: 0.8830 - val_loss: 0.5630 - val_accuracy: 0.8365\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 38s 2ms/step - loss: 0.2969 - accuracy: 0.9149 - val_loss: 0.5273 - val_accuracy: 0.8463\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 36s 2ms/step - loss: 0.2174 - accuracy: 0.9413 - val_loss: 0.5248 - val_accuracy: 0.8430\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 36s 2ms/step - loss: 0.1651 - accuracy: 0.9577 - val_loss: 0.5621 - val_accuracy: 0.8378\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.8534\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 39s 2ms/step - loss: 0.8622 - accuracy: 0.7720 - val_loss: 0.7650 - val_accuracy: 0.7828\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 36s 2ms/step - loss: 0.4143 - accuracy: 0.8825 - val_loss: 0.5519 - val_accuracy: 0.8359\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 37s 2ms/step - loss: 0.2944 - accuracy: 0.9170 - val_loss: 0.6143 - val_accuracy: 0.8162\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 36s 2ms/step - loss: 0.2185 - accuracy: 0.9406 - val_loss: 0.5482 - val_accuracy: 0.8378\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 35s 2ms/step - loss: 0.1685 - accuracy: 0.9559 - val_loss: 0.5609 - val_accuracy: 0.8359\n",
      "Epoch 6/10\n",
      "17130/17130 [==============================] - 36s 2ms/step - loss: 0.1295 - accuracy: 0.9668 - val_loss: 0.5609 - val_accuracy: 0.8374\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.8495\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 39s 2ms/step - loss: 0.7183 - accuracy: 0.7938 - val_loss: 0.6356 - val_accuracy: 0.8069\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 38s 2ms/step - loss: 0.3929 - accuracy: 0.8821 - val_loss: 0.8340 - val_accuracy: 0.7673\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 38s 2ms/step - loss: 0.2689 - accuracy: 0.9186 - val_loss: 0.6596 - val_accuracy: 0.8270\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 40s 2ms/step - loss: 0.1893 - accuracy: 0.9425 - val_loss: 0.6613 - val_accuracy: 0.8339\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 38s 2ms/step - loss: 0.1410 - accuracy: 0.9593 - val_loss: 0.9058 - val_accuracy: 0.8129\n",
      "Epoch 6/10\n",
      "17130/17130 [==============================] - 39s 2ms/step - loss: 0.1066 - accuracy: 0.9681 - val_loss: 0.7848 - val_accuracy: 0.8301\n",
      "145/145 [==============================] - 1s 2ms/step - loss: 0.6052 - accuracy: 0.8392\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 39s 2ms/step - loss: 0.7197 - accuracy: 0.7932 - val_loss: 0.7304 - val_accuracy: 0.7791\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 38s 2ms/step - loss: 0.3897 - accuracy: 0.8821 - val_loss: 0.5932 - val_accuracy: 0.8316\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 38s 2ms/step - loss: 0.2743 - accuracy: 0.9168 - val_loss: 0.5853 - val_accuracy: 0.8457\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 38s 2ms/step - loss: 0.1838 - accuracy: 0.9432 - val_loss: 0.6509 - val_accuracy: 0.8320\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 39s 2ms/step - loss: 0.1411 - accuracy: 0.9576 - val_loss: 0.7230 - val_accuracy: 0.8285\n",
      "145/145 [==============================] - 1s 2ms/step - loss: 0.5263 - accuracy: 0.8472\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 40s 2ms/step - loss: 0.7259 - accuracy: 0.7914 - val_loss: 0.8170 - val_accuracy: 0.7716\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 39s 2ms/step - loss: 0.3899 - accuracy: 0.8831 - val_loss: 0.5720 - val_accuracy: 0.8326\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 38s 2ms/step - loss: 0.2714 - accuracy: 0.9172 - val_loss: 0.7159 - val_accuracy: 0.8129\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 39s 2ms/step - loss: 0.1844 - accuracy: 0.9458 - val_loss: 0.6972 - val_accuracy: 0.8258\n",
      "145/145 [==============================] - 1s 2ms/step - loss: 0.5383 - accuracy: 0.8394\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 41s 2ms/step - loss: 0.7190 - accuracy: 0.7941 - val_loss: 0.6477 - val_accuracy: 0.8081\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 39s 2ms/step - loss: 0.3986 - accuracy: 0.8801 - val_loss: 0.8753 - val_accuracy: 0.7550\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 39s 2ms/step - loss: 0.2749 - accuracy: 0.9181 - val_loss: 0.6510 - val_accuracy: 0.8299\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 40s 2ms/step - loss: 0.1976 - accuracy: 0.9395 - val_loss: 0.7310 - val_accuracy: 0.8262\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 40s 2ms/step - loss: 0.1509 - accuracy: 0.9575 - val_loss: 0.7080 - val_accuracy: 0.8403\n",
      "Epoch 6/10\n",
      "17130/17130 [==============================] - 39s 2ms/step - loss: 0.1106 - accuracy: 0.9673 - val_loss: 0.8016 - val_accuracy: 0.8251\n",
      "Epoch 7/10\n",
      "17130/17130 [==============================] - 39s 2ms/step - loss: 0.0817 - accuracy: 0.9759 - val_loss: 0.8134 - val_accuracy: 0.8291\n",
      "145/145 [==============================] - 1s 3ms/step - loss: 0.6532 - accuracy: 0.8446\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 41s 2ms/step - loss: 0.7203 - accuracy: 0.7942 - val_loss: 0.6832 - val_accuracy: 0.7969\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 41s 2ms/step - loss: 0.3940 - accuracy: 0.8824 - val_loss: 0.5932 - val_accuracy: 0.8328\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 39s 2ms/step - loss: 0.2774 - accuracy: 0.9172 - val_loss: 0.5837 - val_accuracy: 0.8455\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 39s 2ms/step - loss: 0.1911 - accuracy: 0.9414 - val_loss: 0.6501 - val_accuracy: 0.8361\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 39s 2ms/step - loss: 0.1487 - accuracy: 0.9568 - val_loss: 0.7541 - val_accuracy: 0.8260\n",
      "145/145 [==============================] - 1s 2ms/step - loss: 0.5264 - accuracy: 0.8439\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 42s 2ms/step - loss: 0.7250 - accuracy: 0.7951 - val_loss: 0.7928 - val_accuracy: 0.7766\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 41s 2ms/step - loss: 0.3980 - accuracy: 0.8806 - val_loss: 0.5824 - val_accuracy: 0.8312\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 39s 2ms/step - loss: 0.2763 - accuracy: 0.9170 - val_loss: 0.7105 - val_accuracy: 0.8088\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 39s 2ms/step - loss: 0.1877 - accuracy: 0.9446 - val_loss: 0.7074 - val_accuracy: 0.8270\n",
      "145/145 [==============================] - 1s 2ms/step - loss: 0.5502 - accuracy: 0.8383\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 53s 3ms/step - loss: 0.7506 - accuracy: 0.7816 - val_loss: 0.6878 - val_accuracy: 0.7963\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 43s 3ms/step - loss: 0.4410 - accuracy: 0.8672 - val_loss: 0.9514 - val_accuracy: 0.7494\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 44s 3ms/step - loss: 0.3174 - accuracy: 0.9055 - val_loss: 0.8017 - val_accuracy: 0.8023\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 41s 2ms/step - loss: 0.2432 - accuracy: 0.9283 - val_loss: 0.8257 - val_accuracy: 0.8085\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 41s 2ms/step - loss: 0.1777 - accuracy: 0.9480 - val_loss: 0.9525 - val_accuracy: 0.8079\n",
      "Epoch 6/10\n",
      "17130/17130 [==============================] - 40s 2ms/step - loss: 0.1368 - accuracy: 0.9596 - val_loss: 0.8585 - val_accuracy: 0.8278\n",
      "Epoch 7/10\n",
      "17130/17130 [==============================] - 41s 2ms/step - loss: 0.1106 - accuracy: 0.9678 - val_loss: 0.9339 - val_accuracy: 0.8309\n",
      "Epoch 8/10\n",
      "17130/17130 [==============================] - 40s 2ms/step - loss: 0.0889 - accuracy: 0.9740 - val_loss: 1.0200 - val_accuracy: 0.8239\n",
      "Epoch 9/10\n",
      "17130/17130 [==============================] - 42s 2ms/step - loss: 0.0712 - accuracy: 0.9797 - val_loss: 1.1083 - val_accuracy: 0.8309\n",
      "145/145 [==============================] - 1s 2ms/step - loss: 0.9102 - accuracy: 0.8401\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 44s 3ms/step - loss: 0.7515 - accuracy: 0.7823 - val_loss: 0.7437 - val_accuracy: 0.7758\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 40s 2ms/step - loss: 0.4352 - accuracy: 0.8699 - val_loss: 0.6169 - val_accuracy: 0.8295\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 41s 2ms/step - loss: 0.3203 - accuracy: 0.9044 - val_loss: 0.6477 - val_accuracy: 0.8390\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 40s 2ms/step - loss: 0.2313 - accuracy: 0.9306 - val_loss: 0.7952 - val_accuracy: 0.8187\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 40s 2ms/step - loss: 0.1809 - accuracy: 0.9452 - val_loss: 0.7950 - val_accuracy: 0.8227\n",
      "145/145 [==============================] - 1s 2ms/step - loss: 0.5906 - accuracy: 0.8381\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 41s 2ms/step - loss: 0.7586 - accuracy: 0.7784 - val_loss: 0.8686 - val_accuracy: 0.7496\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 41s 2ms/step - loss: 0.4309 - accuracy: 0.8715 - val_loss: 0.6856 - val_accuracy: 0.8197\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 40s 2ms/step - loss: 0.3164 - accuracy: 0.9070 - val_loss: 0.7226 - val_accuracy: 0.8137\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 42s 2ms/step - loss: 0.2257 - accuracy: 0.9331 - val_loss: 0.7645 - val_accuracy: 0.8197\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.6410 - accuracy: 0.8256\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 49s 3ms/step - loss: 0.7675 - accuracy: 0.7817 - val_loss: 0.7183 - val_accuracy: 0.7913\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 50s 3ms/step - loss: 0.4577 - accuracy: 0.8652 - val_loss: 0.9382 - val_accuracy: 0.7440\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 46s 3ms/step - loss: 0.3298 - accuracy: 0.9048 - val_loss: 0.8529 - val_accuracy: 0.7913\n",
      "145/145 [==============================] - 1s 3ms/step - loss: 0.6805 - accuracy: 0.8034\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 42s 2ms/step - loss: 0.7689 - accuracy: 0.7796 - val_loss: 0.7906 - val_accuracy: 0.7656\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 41s 2ms/step - loss: 0.4499 - accuracy: 0.8697 - val_loss: 0.6359 - val_accuracy: 0.8293\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 42s 2ms/step - loss: 0.3313 - accuracy: 0.9042 - val_loss: 0.6618 - val_accuracy: 0.8351\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 46s 3ms/step - loss: 0.2491 - accuracy: 0.9288 - val_loss: 0.7177 - val_accuracy: 0.8289\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 48s 3ms/step - loss: 0.2031 - accuracy: 0.9416 - val_loss: 0.7893 - val_accuracy: 0.8287\n",
      "145/145 [==============================] - 1s 3ms/step - loss: 0.5986 - accuracy: 0.8392\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 44s 3ms/step - loss: 0.7762 - accuracy: 0.7796 - val_loss: 0.8005 - val_accuracy: 0.7654\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 42s 2ms/step - loss: 0.4526 - accuracy: 0.8686 - val_loss: 0.7088 - val_accuracy: 0.8166\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 42s 2ms/step - loss: 0.3361 - accuracy: 0.9022 - val_loss: 0.7232 - val_accuracy: 0.8144\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 41s 2ms/step - loss: 0.2476 - accuracy: 0.9289 - val_loss: 0.8564 - val_accuracy: 0.8104\n",
      "145/145 [==============================] - 1s 2ms/step - loss: 0.6715 - accuracy: 0.8138\n"
     ]
    }
   ],
   "source": [
    "hidden_num_width_pretrained_featrues = {}\n",
    "for hidden_num in hidden_nums:\n",
    "    for hidden_width in hidden_widths:\n",
    "        results = evaluate_model(tokenizer, label_encoder, 1, \n",
    "                                 X_train_features_1, y, \n",
    "                                 dev_data_features_1, \n",
    "                                 X_devtest_features_1,y_devtest,\n",
    "                                 features=features_train, \n",
    "                                 embedding_matrix=embedding_matrix,\n",
    "                                 hidden_num=hidden_num, hidden_width=hidden_width,\n",
    "                                 batch_size=1)\n",
    "        hidden_num_width_pretrained_featrues[(hidden_num, hidden_width)] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>21</th>\n",
       "      <th>42</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>256</th>\n",
       "      <td>0.850399</td>\n",
       "      <td>0.853417</td>\n",
       "      <td>0.849537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>0.850399</td>\n",
       "      <td>0.853417</td>\n",
       "      <td>0.849537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>256</th>\n",
       "      <td>0.839189</td>\n",
       "      <td>0.847165</td>\n",
       "      <td>0.839405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>0.844579</td>\n",
       "      <td>0.843932</td>\n",
       "      <td>0.838327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>256</th>\n",
       "      <td>0.840052</td>\n",
       "      <td>0.838112</td>\n",
       "      <td>0.825609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>0.803406</td>\n",
       "      <td>0.839189</td>\n",
       "      <td>0.813753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         21        42\n",
       "0 256  0.850399  0.853417  0.849537\n",
       "  512  0.850399  0.853417  0.849537\n",
       "1 256  0.839189  0.847165  0.839405\n",
       "  512  0.844579  0.843932  0.838327\n",
       "2 256  0.840052  0.838112  0.825609\n",
       "  512  0.803406  0.839189  0.813753"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(hidden_num_width_pretrained_featrues).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Surprisingly, when number of hidden layer = 0, the model performs the best. Increasing the hidden width does not show consistent improvement on the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Different nonlinearities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_activations = ['linear', 'tanh', 'relu', 'sigmoid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 34s 2ms/step - loss: 0.7587 - accuracy: 0.7860 - val_loss: 0.7175 - val_accuracy: 0.7955\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 34s 2ms/step - loss: 0.4235 - accuracy: 0.8770 - val_loss: 0.9651 - val_accuracy: 0.7513\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 35s 2ms/step - loss: 0.2978 - accuracy: 0.9132 - val_loss: 0.6801 - val_accuracy: 0.8251\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 38s 2ms/step - loss: 0.2166 - accuracy: 0.9374 - val_loss: 0.7747 - val_accuracy: 0.8187\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 33s 2ms/step - loss: 0.1783 - accuracy: 0.9518 - val_loss: 0.7079 - val_accuracy: 0.8312\n",
      "Epoch 6/10\n",
      "17130/17130 [==============================] - 33s 2ms/step - loss: 0.1306 - accuracy: 0.9663 - val_loss: 0.8838 - val_accuracy: 0.8090\n",
      "Epoch 7/10\n",
      "17130/17130 [==============================] - 33s 2ms/step - loss: 0.1102 - accuracy: 0.9687 - val_loss: 0.8774 - val_accuracy: 0.8249\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.6314 - accuracy: 0.8429\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 32s 2ms/step - loss: 0.7536 - accuracy: 0.7880 - val_loss: 0.7382 - val_accuracy: 0.7866\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 32s 2ms/step - loss: 0.4158 - accuracy: 0.8777 - val_loss: 0.5890 - val_accuracy: 0.8314\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 32s 2ms/step - loss: 0.3006 - accuracy: 0.9118 - val_loss: 0.5901 - val_accuracy: 0.8451\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 39s 2ms/step - loss: 0.2170 - accuracy: 0.9363 - val_loss: 0.6763 - val_accuracy: 0.8332\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 36s 2ms/step - loss: 0.1666 - accuracy: 0.9538 - val_loss: 0.7821 - val_accuracy: 0.8264\n",
      "145/145 [==============================] - 1s 2ms/step - loss: 0.5368 - accuracy: 0.8418\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 36s 2ms/step - loss: 0.7559 - accuracy: 0.7881 - val_loss: 0.7808 - val_accuracy: 0.7770\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 36s 2ms/step - loss: 0.4186 - accuracy: 0.8770 - val_loss: 0.5990 - val_accuracy: 0.8274\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 36s 2ms/step - loss: 0.2973 - accuracy: 0.9148 - val_loss: 0.7208 - val_accuracy: 0.8069\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 34s 2ms/step - loss: 0.2120 - accuracy: 0.9396 - val_loss: 0.7242 - val_accuracy: 0.8220\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.5655 - accuracy: 0.8360\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 35s 2ms/step - loss: 0.7301 - accuracy: 0.7887 - val_loss: 0.6208 - val_accuracy: 0.8114\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 36s 2ms/step - loss: 0.3892 - accuracy: 0.8820 - val_loss: 0.8526 - val_accuracy: 0.7610\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 35s 2ms/step - loss: 0.2643 - accuracy: 0.9207 - val_loss: 0.6506 - val_accuracy: 0.8237\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 36s 2ms/step - loss: 0.1849 - accuracy: 0.9439 - val_loss: 0.6478 - val_accuracy: 0.8388\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 35s 2ms/step - loss: 0.1380 - accuracy: 0.9586 - val_loss: 0.6966 - val_accuracy: 0.8388\n",
      "Epoch 6/10\n",
      "17130/17130 [==============================] - 35s 2ms/step - loss: 0.1016 - accuracy: 0.9680 - val_loss: 0.7552 - val_accuracy: 0.8251\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.5968 - accuracy: 0.8362\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 36s 2ms/step - loss: 0.7283 - accuracy: 0.7877 - val_loss: 0.7359 - val_accuracy: 0.7702\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 35s 2ms/step - loss: 0.3871 - accuracy: 0.8832 - val_loss: 0.5922 - val_accuracy: 0.8268\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 34s 2ms/step - loss: 0.2701 - accuracy: 0.9179 - val_loss: 0.5707 - val_accuracy: 0.8444\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 35s 2ms/step - loss: 0.1825 - accuracy: 0.9434 - val_loss: 0.6191 - val_accuracy: 0.8372\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 39s 2ms/step - loss: 0.1344 - accuracy: 0.9598 - val_loss: 0.7457 - val_accuracy: 0.8218\n",
      "145/145 [==============================] - 1s 2ms/step - loss: 0.5130 - accuracy: 0.8444\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 37s 2ms/step - loss: 0.7339 - accuracy: 0.7873 - val_loss: 0.8136 - val_accuracy: 0.7756\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 31s 2ms/step - loss: 0.3880 - accuracy: 0.8824 - val_loss: 0.5627 - val_accuracy: 0.8388\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 29s 2ms/step - loss: 0.2687 - accuracy: 0.9190 - val_loss: 0.7167 - val_accuracy: 0.8073\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 28s 2ms/step - loss: 0.1816 - accuracy: 0.9464 - val_loss: 0.6816 - val_accuracy: 0.8216\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.8441\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 28s 2ms/step - loss: 0.8009 - accuracy: 0.7687 - val_loss: 0.7005 - val_accuracy: 0.7768\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 28s 2ms/step - loss: 0.4221 - accuracy: 0.8719 - val_loss: 0.8098 - val_accuracy: 0.7735\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 28s 2ms/step - loss: 0.3095 - accuracy: 0.9056 - val_loss: 0.6183 - val_accuracy: 0.8264\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 29s 2ms/step - loss: 0.2286 - accuracy: 0.9316 - val_loss: 0.6109 - val_accuracy: 0.8324\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 29s 2ms/step - loss: 0.1734 - accuracy: 0.9493 - val_loss: 1.0994 - val_accuracy: 0.7834\n",
      "Epoch 6/10\n",
      "17130/17130 [==============================] - 30s 2ms/step - loss: 0.1336 - accuracy: 0.9607 - val_loss: 0.8521 - val_accuracy: 0.8085\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.5840 - accuracy: 0.8370\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 34s 2ms/step - loss: 0.7878 - accuracy: 0.7715 - val_loss: 0.6911 - val_accuracy: 0.7855\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 27s 2ms/step - loss: 0.4198 - accuracy: 0.8716 - val_loss: 0.5922 - val_accuracy: 0.8206\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 28s 2ms/step - loss: 0.3045 - accuracy: 0.9062 - val_loss: 0.5711 - val_accuracy: 0.8484\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 29s 2ms/step - loss: 0.2195 - accuracy: 0.9318 - val_loss: 0.6296 - val_accuracy: 0.8266\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 29s 2ms/step - loss: 0.1743 - accuracy: 0.9485 - val_loss: 0.8754 - val_accuracy: 0.7944\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.8506\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 31s 2ms/step - loss: 0.8013 - accuracy: 0.7670 - val_loss: 0.8188 - val_accuracy: 0.7606\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 30s 2ms/step - loss: 0.4178 - accuracy: 0.8728 - val_loss: 0.6318 - val_accuracy: 0.8162\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 28s 2ms/step - loss: 0.3061 - accuracy: 0.9064 - val_loss: 0.6526 - val_accuracy: 0.8083\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 28s 2ms/step - loss: 0.2235 - accuracy: 0.9332 - val_loss: 0.6872 - val_accuracy: 0.8227\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 30s 2ms/step - loss: 0.1696 - accuracy: 0.9495 - val_loss: 1.0187 - val_accuracy: 0.7851\n",
      "Epoch 6/10\n",
      "17130/17130 [==============================] - 29s 2ms/step - loss: 0.1384 - accuracy: 0.9591 - val_loss: 0.7378 - val_accuracy: 0.8318\n",
      "Epoch 7/10\n",
      "17130/17130 [==============================] - 30s 2ms/step - loss: 0.1068 - accuracy: 0.9714 - val_loss: 0.8273 - val_accuracy: 0.8334\n",
      "Epoch 8/10\n",
      "17130/17130 [==============================] - 30s 2ms/step - loss: 0.0799 - accuracy: 0.9764 - val_loss: 0.8603 - val_accuracy: 0.8330\n",
      "Epoch 9/10\n",
      "17130/17130 [==============================] - 28s 2ms/step - loss: 0.0640 - accuracy: 0.9821 - val_loss: 0.9334 - val_accuracy: 0.8415\n",
      "Epoch 10/10\n",
      "17130/17130 [==============================] - 29s 2ms/step - loss: 0.0628 - accuracy: 0.9813 - val_loss: 0.8775 - val_accuracy: 0.8380\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.7716 - accuracy: 0.8467\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 30s 2ms/step - loss: 1.1604 - accuracy: 0.6656 - val_loss: 0.7366 - val_accuracy: 0.7801\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 28s 2ms/step - loss: 0.4834 - accuracy: 0.8589 - val_loss: 0.7272 - val_accuracy: 0.7882\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 28s 2ms/step - loss: 0.3351 - accuracy: 0.9013 - val_loss: 0.5798 - val_accuracy: 0.8343\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 29s 2ms/step - loss: 0.2459 - accuracy: 0.9295 - val_loss: 0.5947 - val_accuracy: 0.8353\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 28s 2ms/step - loss: 0.1849 - accuracy: 0.9478 - val_loss: 0.6104 - val_accuracy: 0.8334\n",
      "Epoch 6/10\n",
      "17130/17130 [==============================] - 29s 2ms/step - loss: 0.1439 - accuracy: 0.9595 - val_loss: 0.6417 - val_accuracy: 0.8320\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.8418\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 30s 2ms/step - loss: 1.1421 - accuracy: 0.6778 - val_loss: 0.7950 - val_accuracy: 0.7530\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 30s 2ms/step - loss: 0.4812 - accuracy: 0.8632 - val_loss: 0.6010 - val_accuracy: 0.8175\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 29s 2ms/step - loss: 0.3375 - accuracy: 0.9022 - val_loss: 0.5508 - val_accuracy: 0.8401\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 30s 2ms/step - loss: 0.2454 - accuracy: 0.9273 - val_loss: 0.5732 - val_accuracy: 0.8336\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 31s 2ms/step - loss: 0.1836 - accuracy: 0.9481 - val_loss: 0.6084 - val_accuracy: 0.8322\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.5083 - accuracy: 0.8476\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 30s 2ms/step - loss: 1.1590 - accuracy: 0.6644 - val_loss: 0.8526 - val_accuracy: 0.7527\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 29s 2ms/step - loss: 0.4833 - accuracy: 0.8620 - val_loss: 0.5943 - val_accuracy: 0.8253\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 30s 2ms/step - loss: 0.3378 - accuracy: 0.9030 - val_loss: 0.6364 - val_accuracy: 0.8075\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 29s 2ms/step - loss: 0.2459 - accuracy: 0.9297 - val_loss: 0.6150 - val_accuracy: 0.8214\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.5714 - accuracy: 0.8325\n"
     ]
    }
   ],
   "source": [
    "hidden_actv_pretrained_features = {}\n",
    "for hidden_activation in hidden_activations:\n",
    "    results = evaluate_model(tokenizer, label_encoder, 1, \n",
    "                             X_train_features_1, y, \n",
    "                             dev_data_features_1, \n",
    "                             X_devtest_features_1,y_devtest,\n",
    "                             features=features_train, \n",
    "                             embedding_matrix=embedding_matrix,\n",
    "                             hidden_activation=hidden_activation,\n",
    "                             batch_size=1)\n",
    "    hidden_actv_pretrained_features[hidden_activation] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>21</th>\n",
       "      <th>42</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>linear</th>\n",
       "      <td>0.842854</td>\n",
       "      <td>0.841776</td>\n",
       "      <td>0.835956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tanh</th>\n",
       "      <td>0.836172</td>\n",
       "      <td>0.844363</td>\n",
       "      <td>0.844147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relu</th>\n",
       "      <td>0.837034</td>\n",
       "      <td>0.850614</td>\n",
       "      <td>0.846734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigmoid</th>\n",
       "      <td>0.841776</td>\n",
       "      <td>0.847596</td>\n",
       "      <td>0.832507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         21        42\n",
       "linear   0.842854  0.841776  0.835956\n",
       "tanh     0.836172  0.844363  0.844147\n",
       "relu     0.837034  0.850614  0.846734\n",
       "sigmoid  0.841776  0.847596  0.832507"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(hidden_actv_pretrained_features).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With fixed number of layer (1) and layer width (128), for seed=0, linear has the best performance, For seed=21, relu has the best performance. For seed=42, relu has the best performance again. Overall, relu has the best performance across random seeds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### w = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = preprocess_x(tokens, 2, tokenizer)\n",
    "X_dev_2 = preprocess_x(tokens_dev, 2, tokenizer)\n",
    "X_devtest_2 = preprocess_x(tokens_devtest, 2, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data_2 = (X_dev_2, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features_2 = [X_2, features_train]\n",
    "dev_data_features_2 = ([X_dev_2, features_dev], y_dev)\n",
    "X_devtest_features_2 = [X_devtest_2, features_devtest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 41s 2ms/step - loss: 0.8515 - accuracy: 0.7723 - val_loss: 0.6328 - val_accuracy: 0.8154\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 38s 2ms/step - loss: 0.4048 - accuracy: 0.8853 - val_loss: 0.6838 - val_accuracy: 0.7990\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 38s 2ms/step - loss: 0.2784 - accuracy: 0.9203 - val_loss: 0.5564 - val_accuracy: 0.8357\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 31s 2ms/step - loss: 0.1983 - accuracy: 0.9470 - val_loss: 0.5365 - val_accuracy: 0.8399\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 29s 2ms/step - loss: 0.1464 - accuracy: 0.9636 - val_loss: 0.5441 - val_accuracy: 0.8397\n",
      "Epoch 6/10\n",
      "17130/17130 [==============================] - 33s 2ms/step - loss: 0.1084 - accuracy: 0.9746 - val_loss: 0.5486 - val_accuracy: 0.8405\n",
      "Epoch 7/10\n",
      "17130/17130 [==============================] - 33s 2ms/step - loss: 0.0825 - accuracy: 0.9814 - val_loss: 0.5578 - val_accuracy: 0.8428\n",
      "Epoch 8/10\n",
      "17130/17130 [==============================] - 34s 2ms/step - loss: 0.0646 - accuracy: 0.9876 - val_loss: 0.5803 - val_accuracy: 0.8378\n",
      "Epoch 9/10\n",
      "17130/17130 [==============================] - 26s 2ms/step - loss: 0.0493 - accuracy: 0.9912 - val_loss: 0.5984 - val_accuracy: 0.8419\n",
      "145/145 [==============================] - 0s 986us/step - loss: 0.5178 - accuracy: 0.8526\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 33s 2ms/step - loss: 0.8573 - accuracy: 0.7734 - val_loss: 0.7039 - val_accuracy: 0.7884\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 36s 2ms/step - loss: 0.4013 - accuracy: 0.8860 - val_loss: 0.5580 - val_accuracy: 0.8332\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 32s 2ms/step - loss: 0.2810 - accuracy: 0.9218 - val_loss: 0.5212 - val_accuracy: 0.8448\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 29s 2ms/step - loss: 0.1970 - accuracy: 0.9470 - val_loss: 0.5197 - val_accuracy: 0.8421\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 29s 2ms/step - loss: 0.1444 - accuracy: 0.9636 - val_loss: 0.5474 - val_accuracy: 0.8388\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.4912 - accuracy: 0.8534\n",
      "Epoch 1/10\n",
      "17130/17130 [==============================] - 28s 2ms/step - loss: 0.8562 - accuracy: 0.7698 - val_loss: 0.7689 - val_accuracy: 0.7841\n",
      "Epoch 2/10\n",
      "17130/17130 [==============================] - 27s 2ms/step - loss: 0.4004 - accuracy: 0.8865 - val_loss: 0.5512 - val_accuracy: 0.8330\n",
      "Epoch 3/10\n",
      "17130/17130 [==============================] - 28s 2ms/step - loss: 0.2785 - accuracy: 0.9215 - val_loss: 0.6182 - val_accuracy: 0.8185\n",
      "Epoch 4/10\n",
      "17130/17130 [==============================] - 31s 2ms/step - loss: 0.1957 - accuracy: 0.9462 - val_loss: 0.5369 - val_accuracy: 0.8378\n",
      "Epoch 5/10\n",
      "17130/17130 [==============================] - 29s 2ms/step - loss: 0.1430 - accuracy: 0.9633 - val_loss: 0.5570 - val_accuracy: 0.8370\n",
      "Epoch 6/10\n",
      "17130/17130 [==============================] - 29s 2ms/step - loss: 0.1042 - accuracy: 0.9743 - val_loss: 0.5577 - val_accuracy: 0.8392\n",
      "Epoch 7/10\n",
      "17130/17130 [==============================] - 29s 2ms/step - loss: 0.0817 - accuracy: 0.9823 - val_loss: 0.5794 - val_accuracy: 0.8409\n",
      "Epoch 8/10\n",
      "17130/17130 [==============================] - 29s 2ms/step - loss: 0.0629 - accuracy: 0.9879 - val_loss: 0.5662 - val_accuracy: 0.8440\n",
      "Epoch 9/10\n",
      "17130/17130 [==============================] - 29s 2ms/step - loss: 0.0493 - accuracy: 0.9919 - val_loss: 0.5733 - val_accuracy: 0.8446\n",
      "Epoch 10/10\n",
      "17130/17130 [==============================] - 31s 2ms/step - loss: 0.0392 - accuracy: 0.9945 - val_loss: 0.5824 - val_accuracy: 0.8455\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.8526\n"
     ]
    }
   ],
   "source": [
    "results_2_pretrained_features_0 = evaluate_model(tokenizer, label_encoder, 2, \n",
    "                                               X_train_features_2, y, \n",
    "                                               dev_data_features_2, \n",
    "                                               X_devtest_features_2,y_devtest,\n",
    "                                               embedding_matrix=embedding_matrix, \n",
    "                                               features=features_train,\n",
    "                                               hidden_num=0,\n",
    "                                               batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.852554440498352, 21: 0.8534166812896729, 42: 0.852554440498352}"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_2_pretrained_features_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using number of hidden layer=0, pretrained embeddings, and features, set w = 2, the model's performance is consistantly improved to have accuracy 85%-86%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
